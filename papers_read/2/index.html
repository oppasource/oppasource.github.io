<!DOCTYPE HTML>
<html>

<head>
  <title>A Deep Reinforced Model for Abstractive Summarization</title>

  <script
    src="https://code.jquery.com/jquery-3.3.1.js"
    
    crossorigin="anonymous">
</script>
<script> 
$(function(){
  $("#header1").load("/header1.html"); 
  $("#footer1").load("/footer1.html"); 
});
</script> 

  <meta name="description" content="research papers read" />
  <meta name="keywords" content="website keywords, website keywords" />
  <meta http-equiv="content-type" content="text/html; charset=windows-1252" />
  <link rel="stylesheet" type="text/css" href="../style/style.css" title="style" />
</head>

<body>
  <div id="main">
    <div id="header1"></div>
    <div id="content_header"></div>
    <div id="site_content">
      <div id="content">
        <!-- insert the page content here -->
        <h1><strong>A Deep Reinforced Model for Abstractive Summarization</strong></h1>
        <h2>"What" part of the paper</h2> 
        <p>Trying to overcome the problem of repetitive and incoherent phrases in summaries generated, a novel intra-attention model is proposed that takes into account the encoder states and also the decoder states i.e. summary that has already been generated till prediction sepeartely. A new training method which in addition to the standard supervised word prediction, also combines Reinforcement Learning.</p>

        <h2>"How" part of the paper</h2>
        <p><strong><i>Intra-Temporal on input sequence</i></strong> is something they used to consider attention over encoding hidden states with the current decoding state and previous word.</p>

        <p>Attention weight for t<sup>th</sup> decoding state and i<sup>th</sup> encoding state is calculated using the following:</p>

        <span class="center"><img src="1.png" alt="something wrong" /></span>

        <p>f can be any function returning scalar, they used bilinear function. It can also be something as simple as dot product as well.</p>

        <span class="center"><img src="2.png" alt="something wrong" /></span>

        <p>Attention weights are normalized to penalize the input tokens that have obtained high attention scores in past decoding steps.</p>

        <span class="center"><img src="3.png" alt="something wrong" /></span>

        <p>Finally the normalized attention scores and context vector are calculated</p>

        <span class="left"><img src="4.png" alt="something wrong" /></span>
        <span class="right"><img src="5.png" alt="something wrong" /></span>


        <br/><br/><br/><br/><br/><br/>
        <hr><br/>

        <p>Decoder can still generated repeated phrases, so for this they try to incorporate the information about previously decoded information using <strong><i>Intra-Decoder Attention.</i></strong> So along with computing encoder context vector with each decoding time step, they also compute decoder context vector. Decoder context vector for first time step is made to be zeros, for <i>t > 1,</i> they use the following steps:</p>

        <span class="center"><img src="6.png" alt="something wrong"/></span>
        <span class="center"><img src="7.png" alt="something wrong"/></span>
        <span class="center"><img src="8.png" alt="something wrong"/></span>

        <hr><br/>

        <p>The whole model with encoder and decoder context vector is show below</p>

        <span class="center"><img src="9.png" alt="something wrong" width="100%" height="100%"/></span>

        <hr><br/>

        <p>For <strong><i>Token Generation</i></strong> step, they use token-generation softmax layer or a pointer mechanism to copy rare or unseen words form input sequence. Softmax layer is given as:</p>

        <span class="center"><img src="10.png" alt="something wrong"/></span>

        <p>Pointer mechanism uses the attention weights as probability distribution to copy input token.</p>

        <span class="center"><img src="11.png" alt="something wrong"/></span>

        <p>The probabilty of using pointer mechanism is given as:</p>

        <span class="center"><img src="12.png" alt="something wrong"/></span>

        <p>So after combining all the three equations above for token-generation, we get:</p>

        <span class="center"><img src="13.png" alt="something wrong"/></span>

        <hr><br/>

        <p>They also introduced some <strong><i>weight sharing</i></strong> between embedding weight matrix and output weight matrix to get some syntactic and semantic information contained in embedding matrix for output token generation, this was done as:</p>

        <span class="center"><img src="14.png" alt="something wrong"/></span>

        <hr><br/>

        <p><strong><i>Supervised Learning</i></strong> is to minimize the below equation where <i>y<sup>*</sup></i> is the ground truth output sequence.</p>

        <span class="center"><img src="15.png" alt="something wrong"/></span>

        <p>There can be many possible summaries and therefore minimizing maximum-likelihood estimation may not be the best. They propose a <strong><i>Policy Learning</i></strong> method where they sample the output based on the probability distribution at each decoding step, <i>y<sup>s</sup></i>. Also they will have y hat which is the greedy search baseline output. They had a reward function <i>r(y)</i> for output sequence <i>y</i> and groud truth <i>y<sup>*</sup></i> with an evaluation metric.</p>

        <span class="center"><img src="16.png" alt="something wrong"/></span>

        <p>Minimizing above equation is equivalent to maximizing the the conditional likelihood of the sampled sequence <i>y<sup>s</sup></i> if it obtains a higher reward than the baseline y hat, thus increasing the reward expectation of our model. Mixing both objectives, we get:</p>

        <span class="center"><img src="17.png" alt="something wrong"/></span>

        <hr><br/>
        

        <h2>Reference</h2>
        <a href="https://arxiv.org/pdf/1705.04304.pdf">A Deep Reinforced Model for Abstractive Summarization</a>

        <br/><br/>




      </div>
    </div>

    <div id="footer1"></div>
    
  </div>
</body>
</html>
